<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="qSJUmJp4-T1Lz9aVN5PqYy0RLyyLWAThSD6RTUty4S8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Sub-optimal Optimal Portfolios | Simon Ellersgaard Nielsen</title> <meta name="author" content="Simon Ellersgaard Nielsen"> <meta name="description" content="Exploring the effect of parameter uncertainty in optimal asset allocation"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://sellersgaard.github.io/blog/2023/portfolio/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Simon </span>Ellersgaard Nielsen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Sub-optimal Optimal Portfolios</h1> <p class="post-meta">March 27, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/econometrics"> <i class="fas fa-hashtag fa-sm"></i> econometrics</a>   <a href="/blog/tag/trading"> <i class="fas fa-hashtag fa-sm"></i> trading</a>     ·   <a href="/blog/category/portfolio"> <i class="fas fa-tag fa-sm"></i> portfolio</a>   </p> </header> <article class="post-content"> <h3 id="a-perfect-brownian">A perfect Brownian</h3> <p>Imagine you are truthfully told about the functional form of the stochastic equations of motion characterising some set of stocks, with the caveat that you are required to estimate the associated parameters yourself. <em>Prima facie</em>, this complete removal of <a href="https://en.wikipedia.org/wiki/Knightian_uncertainty" rel="external nofollow noopener" target="_blank">Knightian uncertainty</a> sounds like a dream scenario which trivially will allow for what we vaguely can call “perfect trading”. In this piece I want to convince you that things are not quite so straight-forward. In particular, even with a substantial amount of data at your disposal, parameter uncertainty can still undermine theoretically optimal strategies. To cement this point, I will consider the simulated performance of a number of results from <a href="https://en.wikipedia.org/wiki/Modern_portfolio_theory" rel="external nofollow noopener" target="_blank">modern portfolio theory</a>, both in the event that we <em>do</em> and <em>do not</em> have complete information about the input parameters. In a certain sense, this analysis is befitting considering that the father of modern portfolio theory, <a href="https://en.wikipedia.org/wiki/Harry_Markowitz" rel="external nofollow noopener" target="_blank">Harry Markowitz</a>, famously <a href="https://onlinelibrary.wiley.com/doi/10.1002/scin.5591791221" rel="external nofollow noopener" target="_blank">doesn’t practice what he preaches</a>, being instead partial towards “equal weight” diversification.</p> <p>To set the scene, let us suppose that the daily percentage returns of \(K\) assets are multivariate normal, \(\boldsymbol{R}_t \sim \mathcal{N}(\boldsymbol{\mu} \Delta t, \boldsymbol{\Sigma} \Delta t)\), where \(\boldsymbol{\mu} \in \mathbb{R}^K\) is an annualised mean return vector, and \(\boldsymbol{\Sigma} \in \mathbb{R}^{K \times K}\) is an annualised covariance matrix i.e. \(\boldsymbol{\Sigma} \equiv \text{diag}(\boldsymbol{\sigma})\boldsymbol{\varrho}\text{diag}(\boldsymbol{\sigma})\) where \(\boldsymbol{\sigma} \in \mathbb{R}^K\) is a volatility vector, and \(\boldsymbol{\varrho} \in \mathbb{R}^{K \times K}\) is a correlation matrix. \(\Delta t\) scales these quantities into daily terms and is typically set to 1/252 to reflect the average number of trading days in a year.</p> <p>Equivalently, we may write this in price process terms as the dynamics</p> \[\boldsymbol{S}_{t+1} = \boldsymbol{S}_{t} + \text{diag}(\boldsymbol{S}_{t})(\boldsymbol{\mu} \Delta t + \boldsymbol{L} \sqrt{\Delta t} \boldsymbol{Z}),\] <p>where \(\boldsymbol{L}\) is the lower triangular matrix arising from <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition" rel="external nofollow noopener" target="_blank">Cholesky decomposing</a> \(\boldsymbol{\Sigma}\), and \(\boldsymbol{Z}: \Omega \mapsto \mathbb{R}^K\) is an i.i.d. standard normal vector i.e \(\boldsymbol{Z} \sim \mathcal{N}(\boldsymbol{0}, \mathbb{I}_{K})\).</p> <p>For the purpose of this exercise we shall consider five co-moving assets with the following parameter specifications:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">μ</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">])</span> <span class="c1">#mean
</span><span class="n">σ</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span> <span class="c1">#volatility
</span><span class="n">ρ</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">ρ</span> <span class="o">=</span> <span class="n">ρ</span><span class="o">+</span><span class="n">ρ</span><span class="p">.</span><span class="n">T</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">identity</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">μ</span><span class="p">))</span> <span class="c1">#correlation
</span><span class="n">dt</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">252</span> <span class="c1">#1/trading days per year
</span><span class="n">T</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1">#simulation time [years] 
</span><span class="n">r</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1">#risk-free rate 
</span><span class="n">S_0</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">μ</span><span class="p">))</span> <span class="c1">#initial share prices
</span><span class="n">W_0</span> <span class="o">=</span> <span class="mf">1e6</span> <span class="c1">#initial welath
</span></code></pre></div></div> <p>Furthermore, it will be convenient to define the following quantities:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">M</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">μ</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">dt</span><span class="p">)</span>
<span class="n">Σ</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">σ</span><span class="p">)</span><span class="nd">@ρ@np.diag</span><span class="p">(</span><span class="n">σ</span><span class="p">)</span>
<span class="n">Σinv</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">Σ</span><span class="p">)</span>
<span class="n">sqdt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
<span class="n">λ</span><span class="p">,</span> <span class="n">Λ</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">eig</span><span class="p">(</span><span class="n">Σ</span><span class="p">)</span>
<span class="nf">assert </span><span class="p">(</span><span class="n">λ</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="nf">all</span><span class="p">()</span> <span class="c1">#assert positive semi-definite
</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">cholesky</span><span class="p">(</span><span class="n">Σ</span><span class="p">)</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
<span class="n">Sharpe</span> <span class="o">=</span> <span class="p">(</span><span class="n">μ</span><span class="o">-</span><span class="n">r</span><span class="p">)</span><span class="o">/</span><span class="n">σ</span>
</code></pre></div></div> <p>Finally, to simulate stock paths according to these inputs we can use the following vectorised function:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">multi_brownian_sim</span><span class="p">(</span><span class="n">seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">]:</span>

    <span class="k">if</span> <span class="n">seed</span><span class="p">:</span>
        <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sqdt</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">L</span><span class="nd">@dW</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span><span class="n">μ</span><span class="o">*</span><span class="n">dt</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)).</span><span class="n">T</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span><span class="p">.</span><span class="n">T</span>
    <span class="n">ret</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">S_0</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">ret</span><span class="p">.</span><span class="nf">cumprod</span><span class="p">()</span> <span class="c1">#levels
</span>    <span class="n">dfr</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">diff</span><span class="p">()</span><span class="o">/</span><span class="n">df</span><span class="p">.</span><span class="nf">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)).</span><span class="nf">dropna</span><span class="p">()</span> <span class="c1">#returns 
</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">dfr</span>
</code></pre></div></div> <p>A single run of this yields something along the lines below:</p> <figure> <picture> <img src="/assets/img/brownian.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="estimating-parameters">Estimating parameters</h3> <p>Alright, suppose you are handed the data for these paths above and informed that returns are multivariate normal. What do you conclude? Well, you’ll probably find the unbiased estimators \(\{\hat{\boldsymbol{\mu}}, \hat{\boldsymbol{\sigma}}, \hat{\boldsymbol{\varrho}} \}\) as displayed in the 2nd column in the tables below. The noteworthy part here is how much some of these appear amiss vis-à-vis their population counterparts. So much so that one <em>almost suspects</em> that something is messed up with the data-generating process per se. To assure you this is not the case, we will do a couple of exercises: first, we will compute two-sigma confidence intervals for our estimators, and second, we will sample from the data-generating process repeatedly and show that the averages over the estimators indeed are congruent with the true underlying dynamics.</p> <p>Confidence intervals for \(\hat{\boldsymbol{\mu}}\) and \(\hat{\boldsymbol{\sigma}}^2\) can be computed using the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem" rel="external nofollow noopener" target="_blank">central limit theorem</a>: indeed, it is straightforward to show that \(\sqrt{N}(\hat{\mu}_i - \mu_i) \sim \mathcal{N}(0, \sigma_i^2)\) and \(\sqrt{N}(\hat{\sigma}_i^2 - \sigma_i^2) \sim \mathcal{N}(0, 2\sigma_i^4)\) where \(N\) is the number of observations. Deploying the <a href="https://en.wikipedia.org/wiki/Delta_method" rel="external nofollow noopener" target="_blank">delta method</a> to extract the limiting distribution of \(\hat{\boldsymbol{\sigma}}\) we find that \(\sqrt{N}(\hat{\sigma}_i - \sigma_i) \sim \mathcal{N}(0, \sigma_i^2/2)\). Finally, confidence intervals for \(\hat{\varrho}_{ij}\) can be estimated using the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#Using_the_Fisher_transformation" rel="external nofollow noopener" target="_blank">Fisher transformation</a>.</p> <p>For the Monte Carlo simulation we run the data generating process 1000 times storing the estimators for \(\{\hat{\boldsymbol{\mu}}, \hat{\boldsymbol{\sigma}}, \hat{\boldsymbol{\varrho}} \}\) from each run in order to ultimately study their statistical properties. Per definition, 95% of the confidence intervals we’d compute from repeated sampling should encompass the true population parameters. Notice the expected values (6th column) across these samples align much more closely with the true parameters: a small victory for having the equivalent of 10,000 years’ worth of financial data(!)</p> <table border="1" class="dataframe" width="100%"> <thead> <tr style="text-align: right;"> <th></th> <th>$$\mu$$</th> <th>$$\hat{\mu}$$</th> <th>$$\hat{\mu}-2SE$$</th> <th>$$\hat{\mu}+2SE$$</th> <th>$$\in CI$$</th> <th>$$\mathbb{E}(\mu_{mc})$$</th> <th>$$\min(\mu_{mc})$$</th> <th>$$\max(\mu_{mc})$$</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0.10</td> <td>0.152</td> <td>0.090</td> <td>0.214</td> <td>True</td> <td>0.097</td> <td>0.003</td> <td>0.191</td> </tr> <tr> <th>1</th> <td>0.13</td> <td>0.096</td> <td>-0.000</td> <td>0.192</td> <td>True</td> <td>0.131</td> <td>-0.035</td> <td>0.252</td> </tr> <tr> <th>2</th> <td>0.08</td> <td>0.039</td> <td>-0.024</td> <td>0.103</td> <td>True</td> <td>0.080</td> <td>-0.027</td> <td>0.173</td> </tr> <tr> <th>3</th> <td>0.09</td> <td>0.105</td> <td>0.043</td> <td>0.168</td> <td>True</td> <td>0.089</td> <td>-0.019</td> <td>0.197</td> </tr> <tr> <th>4</th> <td>0.14</td> <td>0.132</td> <td>0.007</td> <td>0.257</td> <td>True</td> <td>0.139</td> <td>-0.039</td> <td>0.339</td> </tr> </tbody> </table> <p><br></p> <table border="1" class="dataframe" width="100%"> <thead> <tr style="text-align: right;"> <th></th> <th>$$\sigma$$</th> <th>$$\hat{\sigma}$$</th> <th>$$\hat{\sigma}-2SE$$</th> <th>$$\hat{\sigma}+2SE$$</th> <th>$$\in CI$$</th> <th>$$\mathbb{E}(\sigma_{mc})$$</th> <th>$$\min(\sigma_{mc})$$</th> <th>$$\max(\sigma_{mc})$$</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0.10</td> <td>0.098</td> <td>0.096</td> <td>0.101</td> <td>True</td> <td>0.10</td> <td>0.096</td> <td>0.104</td> </tr> <tr> <th>1</th> <td>0.15</td> <td>0.152</td> <td>0.147</td> <td>0.156</td> <td>True</td> <td>0.15</td> <td>0.144</td> <td>0.158</td> </tr> <tr> <th>2</th> <td>0.10</td> <td>0.101</td> <td>0.098</td> <td>0.104</td> <td>True</td> <td>0.10</td> <td>0.096</td> <td>0.104</td> </tr> <tr> <th>3</th> <td>0.10</td> <td>0.099</td> <td>0.096</td> <td>0.101</td> <td>True</td> <td>0.10</td> <td>0.095</td> <td>0.104</td> </tr> <tr> <th>4</th> <td>0.20</td> <td>0.198</td> <td>0.192</td> <td>0.203</td> <td>True</td> <td>0.20</td> <td>0.191</td> <td>0.208</td> </tr> </tbody> </table> <p><br></p> <table border="1" class="dataframe" width="100%"> <thead> <tr style="text-align: right;"> <th></th> <th></th> <th>$$\rho$$</th> <th>$$\hat{\rho}$$</th> <th>$$\hat{\rho}-2SE$$</th> <th>$$\hat{\rho}+2SE$$</th> <th>$$\in CI$$</th> <th>$$\mathbb{E}(\rho_{mc})$$</th> <th>$$\min(\rho_{mc})$$</th> <th>$$\max(\rho_{mc})$$</th> </tr> </thead> <tbody> <tr> <th rowspan="4" valign="top">0</th> <th>1</th> <td>0.20</td> <td>0.208</td> <td>0.169</td> <td>0.245</td> <td>True</td> <td>0.200</td> <td>0.146</td> <td>0.260</td> </tr> <tr> <th>2</th> <td>0.30</td> <td>0.292</td> <td>0.256</td> <td>0.328</td> <td>True</td> <td>0.299</td> <td>0.233</td> <td>0.365</td> </tr> <tr> <th>3</th> <td>0.10</td> <td>0.057</td> <td>0.017</td> <td>0.096</td> <td>False</td> <td>0.100</td> <td>0.039</td> <td>0.159</td> </tr> <tr> <th>4</th> <td>0.40</td> <td>0.405</td> <td>0.371</td> <td>0.438</td> <td>True</td> <td>0.400</td> <td>0.340</td> <td>0.456</td> </tr> <tr> <th rowspan="3" valign="top">1</th> <th>2</th> <td>0.50</td> <td>0.483</td> <td>0.452</td> <td>0.513</td> <td>True</td> <td>0.500</td> <td>0.447</td> <td>0.545</td> </tr> <tr> <th>3</th> <td>0.20</td> <td>0.189</td> <td>0.151</td> <td>0.227</td> <td>True</td> <td>0.200</td> <td>0.137</td> <td>0.256</td> </tr> <tr> <th>4</th> <td>0.10</td> <td>0.138</td> <td>0.099</td> <td>0.177</td> <td>True</td> <td>0.100</td> <td>0.037</td> <td>0.163</td> </tr> <tr> <th rowspan="2" valign="top">2</th> <th>3</th> <td>0.10</td> <td>0.124</td> <td>0.085</td> <td>0.163</td> <td>True</td> <td>0.101</td> <td>0.043</td> <td>0.164</td> </tr> <tr> <th>4</th> <td>0.15</td> <td>0.179</td> <td>0.140</td> <td>0.217</td> <td>True</td> <td>0.150</td> <td>0.093</td> <td>0.208</td> </tr> <tr> <th>3</th> <th>4</th> <td>0.20</td> <td>0.199</td> <td>0.160</td> <td>0.237</td> <td>True</td> <td>0.200</td> <td>0.139</td> <td>0.261</td> </tr> </tbody> </table> <p><br> Scanning through the above numbers the most problematic estimator is clearly \(\hat{\boldsymbol{\mu}}\). Intuitively, we can explain this as follows: since \(R_t \equiv (S_t-S_{t-1})/S_{t-1} \approx \ln(S_t)-\ln(S_{t-1})\) it follows that</p> \[\bar{R} \equiv N^{-1} \sum_{i=1}^N R_t \approx N^{-1} \left( \ln(S_T)-\ln(S_{0}) \right),\] <p>i.e. the estimator is a <a href="https://en.wikipedia.org/wiki/Telescoping_series" rel="external nofollow noopener" target="_blank">telescoping series</a> effectively determined by the first and last entry. For “shorter” histories this can be extremely problematic (noisy).</p> <h3 id="the-final-frontier">The final frontier?</h3> <p>To get a sense of the sheer amount of gravity these uncertainties carry, it is helpful to consider the <a href="https://en.wikipedia.org/wiki/Efficient_frontier" rel="external nofollow noopener" target="_blank">efficient frontier</a> i.e. the collection of portfolio constructions which deliver the lowest amount of volatility for a given level of return. A well known result in modern portfolio theory states that this frontier carves out a hyperbola in (standard deviation, mean)-space given by the equation</p> \[\sigma_{\pi}^2(\mu_{\pi}) = \frac{C \mu_{\pi}^2 - 2B \mu_{\pi} + A}{D},\] <p>where \(A \equiv \boldsymbol{\mu}^\intercal \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}\), \(B \equiv \boldsymbol{\mu}^\intercal \boldsymbol{\Sigma}^{-1} \boldsymbol{1}\), \(C \equiv \boldsymbol{1}^\intercal \boldsymbol{\Sigma}^{-1} \boldsymbol{1}\), and \(D \equiv AC-B^2\).</p> <p>The function below allows us to visualise the efficient frontier for arbitrary \(\boldsymbol{\mu}\), \(\boldsymbol{\Sigma}\):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_frontier</span><span class="p">(</span><span class="n">μ_est</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">Σ_est</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">scatter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">muc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>

    <span class="n">σ_est</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">Σ_est</span><span class="p">))</span>
    <span class="n">Σinv_est</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">Σ_est</span><span class="p">)</span>

    <span class="n">A</span> <span class="o">=</span> <span class="n">μ_est</span><span class="nd">@Σinv_est@μ_est</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">μ_est</span><span class="nd">@Σinv_est@I</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">I</span><span class="nd">@Σinv_est@I</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">A</span><span class="o">*</span><span class="n">C</span> <span class="o">-</span> <span class="n">B</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">if</span> <span class="n">μ_est</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">muc</span><span class="p">:</span>
        <span class="n">muc</span> <span class="o">=</span> <span class="n">μ_est</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.1</span>
    <span class="n">mubar</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">muc</span><span class="p">,</span><span class="mf">0.005</span><span class="p">)</span>
    <span class="n">sigbar</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">((</span><span class="n">C</span><span class="o">*</span><span class="nf">pow</span><span class="p">(</span><span class="n">mubar</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="o">*</span><span class="n">mubar</span> <span class="o">+</span> <span class="n">A</span><span class="p">)</span><span class="o">/</span><span class="n">D</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">11</span><span class="p">))</span>

    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">sigbar</span><span class="p">,</span> <span class="n">mubar</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scatter</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">σ_est</span><span class="p">,</span> <span class="n">μ_est</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$\sigma$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$\mu$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Efficient Frontier</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>E.g. for the specified parameters characterising the five assets, this yields the following curve:</p> <figure> <picture> <img src="/assets/img/frontier1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Now let’s consider what happens if \(\boldsymbol{\mu}\) is known <em>a priori</em>, but \(\boldsymbol{\Sigma}\) must be estimated from the data. As above, we’ll repeat the data generating process 1000 times, recomputing the frontier on each iteration, to get a sense of the variability.</p> <figure> <picture> <img src="/assets/img/frontier2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Evidently, while this introduces some estimation error, the overall picture remains “within reason”.</p> <p>Finally, suppose both \(\boldsymbol{\mu}\) are \(\boldsymbol{\Sigma}\) are inferred <em>a posteriori</em>. The Monte Carlo run yields:</p> <figure> <picture> <img src="/assets/img/frontier3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>… which isn’t exactly great.</p> <p>The question remains: to what extent does this actually impact quantitative trading strategies? Well, the efficient frontier does include a couple of portfolios of interest, most notably the <em>minimum variance portfolio</em> and the <em>maximum Sharpe ratio portfolio</em>, both of which plausibly could be adopted by practitioners. Let’s see how such strategies fare in light of our current framework.</p> <h3 id="one-period-optimal-trading-strategies">One-period “optimal” trading strategies</h3> <p>One of the great tragedies of academic finance is the curious disconnect with which it operates from the practical field. Optimisation, for example, is a major division of mathematical finance, yet empirical tests thereof are shockingly scarce. So much so that the <em>enfant terrible</em> of the quant industry, Nassim Taleb, noted in “The Black Swan”:</p> <blockquote> <p><em>“I would not be the first to say that this optimisation set back the social science by reducing it from the intellectual and reflective discipline it was becoming to an attempt at an “exact science”. By “exact science”, I mean a second-rate engineering problem for those who want to pretend that they are in a physics department - so-called physics envy. In other words, an intellectual fraud”.</em></p> </blockquote> <p>To remedy this deplorable situation, let us finally explore how optimal one-period portfolio constructions fare against equal allocation (\(1/K\) diversification). In particular, let us consider whether (I) the minimum variance portfolio<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>:</p> \[\boldsymbol{\pi}_{\text{minvar}} = \frac{\boldsymbol{\Sigma}^{-1} \boldsymbol{1}}{ \boldsymbol{1}^\intercal \boldsymbol{\Sigma}^{-1} \boldsymbol{1}},\] <p>actually delivers a smaller variance than the \(1/K\) benchmark. For reference: \(\boldsymbol{\pi}_{\text{minvar}} \approx (0.32, 0.00, 0.31 , 0.38, -0.01)\). Similarly whether (II) the maximum sharpe ratio portfolio<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>:</p> \[\boldsymbol{\pi}_{\text{maxshp}} = \frac{\boldsymbol{\Sigma}^{-1} (\boldsymbol{\mu}-r\boldsymbol{1})}{ \boldsymbol{1}^\intercal \boldsymbol{\Sigma}^{-1} (\boldsymbol{\mu}-r\boldsymbol{1})},\] <p>actually delivers a higher Sharpe ratio than the \(1/K\) benchmark. For reference: \(\boldsymbol{\pi}_{\text{maxshp}} \approx (0.34, 0.14, 0.14, 0.33, 0.05)\).</p> <p>To analyse these questions, consider the following experimental set-up: Using simulated data we will run five <a href="https://en.wikipedia.org/wiki/Self-financing_portfolio" rel="external nofollow noopener" target="_blank">self-financing portfolios</a> for 10 years, each starting with a million dollar notational. The five strategies under scrutiny are: (i) The \(1/K\) portfolio, (ii) \(\boldsymbol{\pi}_{\text{minvar}}\) with known parameters, (iii) \(\boldsymbol{\pi}_{\text{minvar}}\) with unknown parameters, (iv) \(\boldsymbol{\pi}_{\text{maxshp}}\) with known parameters, and (v) \(\boldsymbol{\pi}_{\text{maxshp}}\) with unknown parameters. All estimated quantities will be based on at least ten years’ worth of history and will be updated weekly. At the end all portfolios will have their variance and Sharpe ratio computed. As usual, we’ll repeat this entire process 1000 times.</p> <p>For a given matrix of simulated returns, the following function computes the wealth paths of the five strategies:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">π_eql</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">/</span><span class="n">M</span> <span class="c1">#equally weighted portfolio
</span><span class="n">π_var</span> <span class="o">=</span> <span class="p">(</span><span class="n">Σinv</span><span class="nd">@I</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">I</span><span class="nd">@Σinv@I</span><span class="p">)</span> <span class="c1">#minimum variance portfolio
</span><span class="n">π_shp</span> <span class="o">=</span> <span class="p">(</span><span class="n">Σinv</span><span class="o">@</span><span class="p">(</span><span class="n">μ</span><span class="o">-</span><span class="n">r</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">I</span><span class="nd">@Σinv</span><span class="o">@</span><span class="p">(</span><span class="n">μ</span><span class="o">-</span><span class="n">r</span><span class="p">))</span> <span class="c1">#optimal sharpe portfolio
</span>
<span class="k">def</span> <span class="nf">wealth_path</span><span class="p">(</span><span class="n">dfr</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">]:</span>

    <span class="n">col</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">W_equal</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">W_minvar</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">W_minvar_est</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">W_sharpe</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">W_sharpe_est</span><span class="sh">'</span><span class="p">,]</span>
    <span class="n">t_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dfw</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">t_test</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">col</span><span class="p">)</span>
    <span class="n">dfw</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">t_test</span><span class="p">[</span><span class="mi">0</span><span class="p">],:]</span> <span class="o">=</span> <span class="n">W_0</span>
    <span class="n">pi_shp_dic</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">pi_var_dic</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">μ_hat_vec</span> <span class="o">=</span> <span class="n">dfr</span><span class="p">.</span><span class="nf">expanding</span><span class="p">().</span><span class="nf">mean</span><span class="p">()</span><span class="o">/</span><span class="n">dt</span>
    <span class="n">Σ_hat_vec</span> <span class="o">=</span> <span class="n">dfr</span><span class="p">.</span><span class="nf">expanding</span><span class="p">().</span><span class="nf">cov</span><span class="p">()</span><span class="o">/</span><span class="n">dt</span>

    <span class="k">for</span> <span class="n">ti</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">t_test</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ti</span><span class="o">%</span><span class="mi">7</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">μ_hat</span> <span class="o">=</span> <span class="n">μ_hat_vec</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">t</span><span class="p">].</span><span class="n">values</span>
            <span class="n">Σ_hat</span> <span class="o">=</span> <span class="n">Σ_hat_vec</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">t</span><span class="p">].</span><span class="n">values</span>
            <span class="n">Σinv_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">Σ_hat</span><span class="p">)</span>
            <span class="n">pi_shp_dic</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Σinv_hat</span><span class="o">@</span><span class="p">(</span><span class="n">μ_hat</span><span class="o">-</span><span class="n">r</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">I</span><span class="nd">@Σinv_hat</span><span class="o">@</span><span class="p">(</span><span class="n">μ_hat</span><span class="o">-</span><span class="n">r</span><span class="p">))</span>
            <span class="n">pi_var_dic</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Σinv_hat</span><span class="nd">@I</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">I</span><span class="nd">@Σinv_hat@I</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pi_shp_dic</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">pi_shp_dic</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">pi_var_dic</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">pi_var_dic</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">ti</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">col_map</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">W_equal</span><span class="sh">'</span><span class="p">:</span> <span class="n">π_eql</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">W_minvar</span><span class="sh">'</span><span class="p">:</span> <span class="n">π_var</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">W_minvar_est</span><span class="sh">'</span><span class="p">:</span> <span class="n">pi_var_dic</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="sh">'</span><span class="s">W_sharpe</span><span class="sh">'</span><span class="p">:</span> <span class="n">π_shp</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">W_sharpe_est</span><span class="sh">'</span><span class="p">:</span> <span class="n">pi_shp_dic</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">col</span><span class="p">:</span>
                <span class="n">dfw</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfw</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">col_map</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="nd">@dfr.loc</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>

    <span class="n">pi_shp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="nf">from_dict</span><span class="p">(</span><span class="n">pi_shp_dic</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">pi_var</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="nf">from_dict</span><span class="p">(</span><span class="n">pi_var_dic</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dfw</span><span class="p">,</span> <span class="n">pi_shp</span><span class="p">,</span> <span class="n">pi_var</span>  
</code></pre></div></div> <p>Here’s one such example, which in itself won’t tell you much:</p> <figure> <picture> <img src="/assets/img/wealth.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>However, once we repeat this enough times a pattern starts to emerge. Specifically, consider the distributive properties of the optimal portfolios <em>less</em> the \(1/K\) benchmark:</p> <table border="1" class="dataframe" width="100%"> <thead> <tr style="text-align: right;"> <th></th> <th> $$\sigma(\boldsymbol{\pi}_{\text{minvar}})-\sigma(\boldsymbol{\pi}_{1/K} )$$ </th> <th> $$\sigma(\hat{\boldsymbol{\pi}}_{\text{minvar}})-\sigma(\boldsymbol{\pi}_{1/K} )$$ </th> <th> $$Shp(\boldsymbol{\pi}_{\text{maxshp}})-Shp(\boldsymbol{\pi}_{1/K} )$$ </th> <th> $$Shp(\hat{\boldsymbol{\pi}}_{\text{maxshp}})-Shp(\boldsymbol{\pi}_{1/K} )$$ </th> </tr> </thead> <tbody> <tr> <th>count</th> <td>1000</td> <td>1000</td> <td>1000</td> <td>1000</td> </tr> <tr> <th>mean</th> <td>-0.015</td> <td>-0.015</td> <td>0.104</td> <td>0.008</td> </tr> <tr> <th>std</th> <td>0.001</td> <td>0.001</td> <td>0.120</td> <td>0.161</td> </tr> <tr> <th>min</th> <td>-0.018</td> <td>-0.018</td> <td>-0.299</td> <td>-0.790</td> </tr> <tr> <th>2.5%</th> <td>-0.017</td> <td>-0.017</td> <td>-0.119</td> <td>-0.308</td> </tr> <tr> <th>50%</th> <td>-0.015</td> <td>-0.015</td> <td>0.105</td> <td>0.003</td> </tr> <tr> <th>97.5%</th> <td>-0.013</td> <td>-0.013</td> <td>0.342</td> <td>0.352</td> </tr> <tr> <th>max</th> <td>-0.013</td> <td>-0.013</td> <td>0.503</td> <td>0.641</td> </tr> <tr> <th># &lt; 0</th> <td>1000</td> <td>1000</td> <td>200</td> <td>493</td> </tr> </tbody> </table> <p><br></p> <p>The take-away here is that the minimum variance portfolio does, in fact, deliver a lower volatility than the equal allocation portfolio - regardless of whether \(\boldsymbol{\Sigma}\) is estimated or not. As for the maximum Sharpe ratio portfolio the situation is more problematic: while 80% of the portfolios with known parameters <em>do</em> outperform the benchmark, there’s little to suggest optimisation actually helps once we introduce estimation into the picture. Again, the culprit is the uncertainty around the \(\hat{\boldsymbol{\mu}}\) estimator.</p> <p>In summary, even under highly idealised circumstances optimal trading strategies may not deliver as expected. Indeed, I would strongly caution against embracing small improvements in portfolio performance from some complicated optimisation process vs. keeping things simple. Markowitz’s \(1/K\) portfolio allocation is a lot less irrational than it initially appears.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>I.e. the solution to \(\min_{\boldsymbol{\pi}} \boldsymbol{\pi}^\intercal \boldsymbol{\Sigma} \boldsymbol{\pi}\) where \(\boldsymbol{\pi}^\intercal \boldsymbol{1}=1\). <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>I.e. the solution to \(\max_{\boldsymbol{\pi}} (\boldsymbol{\pi}^\intercal\mu - r)/\sqrt{\boldsymbol{\pi}^\intercal \boldsymbol{\Sigma} \boldsymbol{\pi}}\) where \(\boldsymbol{\pi}^\intercal \boldsymbol{1}=1\). <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Simon Ellersgaard Nielsen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>