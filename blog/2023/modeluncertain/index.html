<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="qSJUmJp4-T1Lz9aVN5PqYy0RLyyLWAThSD6RTUty4S8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Model Multiplicity | Simon Ellersgaard Nielsen</title> <meta name="author" content="Simon Ellersgaard Nielsen"> <meta name="description" content="Incorporating model uncertainty into your machine learning pipeline"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://sellersgaard.github.io/blog/2023/modeluncertain/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Simon </span>Ellersgaard Nielsen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Model Multiplicity</h1> <p class="post-meta">April 4, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fas fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/blog/tag/probability"> <i class="fas fa-hashtag fa-sm"></i> probability</a>     ·   <a href="/blog/category/modelling"> <i class="fas fa-tag fa-sm"></i> modelling</a>   </p> </header> <article class="post-content"> <figure> <picture> <img src="/assets/img/uncertain2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><em>Probabilistic uncertainty as interpreted by DALL-E 2</em></p> <h3 id="bayesian-model-averaging">Bayesian model averaging</h3> <p>A well-known aphorism attributed to <a href="https://en.wikipedia.org/wiki/George_E._P._Box" rel="external nofollow noopener" target="_blank">George Box</a> states that “<em>all models are wrong, but some are useful</em>”. This observation rings particularly true in systematic investing, where the price action governed by millions of non-cooperating players, ultimately is explained through some sort of reductionist supervised learning problem. Nobody would seriously entertain the view that these models are <em>fundamental</em> or <em>expressively adequate</em>, yet it is common practice to let just a single model guide the trading process based on some performance metric like the out-of-sample mean-squared error. This is potentially troubling given that a less accurate model need not be universally inferior in all of its predictions. Indeed, it is conceivable that some biases cancel each other out if only we marry the predictions made by various models (see e.g. the work by <a href="https://en.wikipedia.org/wiki/Jennifer_A._Hoeting" rel="external nofollow noopener" target="_blank">Jennifer Hoeting</a>). This begs the question: how exactly do we combine said predictions? Intuitively, while simple linear averaging might work, the thought of attributing equal significance to models regardless of their level of performance is clearly distasteful. A somewhat subtler approach would be to weigh a prediction by the evidence of the model, and this is precisely what <em>Bayesian model averaging</em> sets out to do. In this piece I will provide an exegesis of this philosophy, and lay out what I consider to be serious obstacles and how to potentially overcome them.</p> <p>Let \(\boldsymbol{y}=(y_1, y_2, ..., y_N)^\intercal \in \mathbb{R}^{N}\) be a vector of data observations, which we desire to model. Furthermore, suppose we have \(K\) competing models \(\mathbb{M} = \{M_1, M_2, ..., M_K \}\) for \(\boldsymbol{y}\), each of which is characterised by some specific vector of parameters: \(\boldsymbol{\theta}_i = (\theta_{i,1},\theta_{i,2}, ..., \theta_{i,T_i})^\intercal \in \boldsymbol{\Theta}_i \subseteq \mathbb{R}^{T_i}\). The candidate models could be <a href="https://www.theanalysisfactor.com/what-are-nested-models/" rel="external nofollow noopener" target="_blank">nested</a> within the same super-model (e.g. all possible subsets of a multivariate linear regression), although this is <em>not</em> a requirement.</p> <p>Based on observable evidence, what is the probability of any given model? According to <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="external nofollow noopener" target="_blank">Bayes’ theorem</a> it follows that \(\forall i\):</p> <p>\begin{equation}\label{bayes} p(M_i | \boldsymbol{y} ) = \frac{p(\boldsymbol{y}| M_i) p(M_i) }{\sum_{j=1}^K p(\boldsymbol{y}| M_j) p(M_j)}, \end{equation}</p> <p>where \(p(\boldsymbol{y} \vert M_i)\) can be written as</p> <p>\begin{equation}\label{bayes2} p(\boldsymbol{y}| M_i) = \int_{\boldsymbol{\Theta}_i} p(\boldsymbol{y}| \boldsymbol{\theta}_i, M_i) p(\boldsymbol{\theta}_i | M_i) d\boldsymbol{\theta}_i. <br> \end{equation}</p> <p>Here, the probability \(p(M_i)\) signifies our credence in model \(M_i\) before being presented with any available data. Obviously, for any given model, this is an entirely subjective matter, although a popular choice unsurprisingly is that of <a href="https://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors" rel="external nofollow noopener" target="_blank">uniformity</a>: \(\forall i: p(M_i)=1/K\). In a similar vein, the probability \(p(\boldsymbol{\theta}_i | M_i)\) codifies our prior beliefs about how the parameters of model \(M_i\) are distributed, assuming the correctness of that model: again, a matter inherently subjective in nature. While people anchored in the frequentists’ paradigm might find the concept of subjective priors disturbingly nebulous, let me assure you that the importance of priors often is <em>over-stated</em>. Specifically, for sufficiently large \(N\) (no. of observations), sufficiently diffuse priors will be overshadowed by the evidence leading to approximately identical posteriors. The important point is that equation \eqref{bayes} provides a coherent framework for going from no empirical evidence, to looking at the data, to ultimately assigning an evidence based probability score to a given model.</p> <p>Now we can use our collection of posterior probabilities over the space of models \(\mathbb{M}\) to get a sense of “model free” (strictly speaking: model weighted) probabilities: e.g. if \(\Delta\) is some quantity of interest then \(p(\Delta | \boldsymbol{y}) = \sum_{j=1}^K p(\Delta | M_j, \boldsymbol{y}) p(M_j | \boldsymbol{y}).\) E.g. if we are in the business of forecasting, we can get a model-averaged expectation of the next observation using the equation:</p> <p>\begin{equation}\label{expectation} \mathbb{E}[y^* | \boldsymbol{y}] = \sum_{j=1}^K \mathbb{E}[y^* | \boldsymbol{y}, M_j] p(M_j | \boldsymbol{y}).<br> \end{equation}</p> <p>Great, so should we start throwing everything but the kitchen sink when modelling our data? Well, not quite…</p> <h3 id="the-schwarz-approximation">The Schwarz approximation</h3> <p>There’s a rather glaring issue with \eqref{bayes} having to do with computability. For starters, the space of possible models quickly grows almost unimaginably large. For instance, the number of possible linear regressions you can run with 50 input features is well over a quadrillion (\(10^{15}\)). Secondly, finding explicit expression for the posterior distribution may often prove onerous if not downright impossible: instead, computer-intensive numerical methods such as <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="external nofollow noopener" target="_blank">Markov Chain Monte Carlo</a> (MCMC) must be called up. If this in turn must be run repeatedly in a back-testing system, the computational challenges quickly become insurmountable.</p> <p>Neither issue is trivially resolved, but there are a few tricks of the trade commonly employed. E.g. drastic reductions in the model space cardinality are quickly accomplished by (a) excluding models which predict the data far less well than the best model, and (b) throwing out complex models that receive less support from the data, than simpler models [<a href="https://www.jstor.org/stable/2676803" rel="external nofollow noopener" target="_blank">Hoeting et al.</a>]. Meanwhile, to circumvent the MCMC issue, we may follow Gideon Schwarz in approximating the posterior distribution using <a href="https://en.wikipedia.org/wiki/Laplace%27s_method" rel="external nofollow noopener" target="_blank">Laplace’s method</a>.</p> <p>The basic idea is as follows<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>: suppose we take a flat prior on \(\boldsymbol{\Theta}_i\). Furthermore, let \(\ell(\boldsymbol{\theta}) \equiv \log(p(\boldsymbol{y}| \boldsymbol{\theta}_i, M_i) )\) denote the log-likelihood, \(\bar{\ell}\) the mean log-likelihood, and let \(\hat{\boldsymbol{\theta}}_i\) be the maximum likelihood estimator (MLE), then \eqref{bayes2} can be written as</p> \[\begin{aligned} p(\boldsymbol{y} | M_i) &amp;\propto \int_{\boldsymbol{\Theta}_i} e^{N \bar{\ell}(\boldsymbol{\theta}_i)} d\boldsymbol{\theta}_i \\ &amp; \approx e^{\ell(\hat{\boldsymbol{\theta}}_i)} \int_{\boldsymbol{\Theta}_i} e^{-\tfrac{1}{2} (\boldsymbol{\theta}_i - \hat{\boldsymbol{\theta}}_i)^\intercal N\frac{\partial^2 \bar{\ell}(\hat{\boldsymbol{\theta}}_i) }{\partial \boldsymbol{\theta}_i \partial \boldsymbol{\theta}_i^\intercal} (\boldsymbol{\theta}_i - \hat{\boldsymbol{\theta}}_i)} d\boldsymbol{\theta}_i \\ &amp; \approx e^{\ell(\hat{\boldsymbol{\theta}}_i)} (2 \pi)^{-T_i/2} N^{-T_i/2} \det \left(\frac{\partial^2 \bar{\ell}(\hat{\boldsymbol{\theta}}_i) }{\partial \boldsymbol{\theta}_i \partial \boldsymbol{\theta}_i^\intercal} \right)^{1/2}, \end{aligned}\] <p>where the second line uses a <a href="https://en.wikipedia.org/wiki/Taylor_series" rel="external nofollow noopener" target="_blank">Taylor expansion</a> around the MLE, and the third line executes the <a href="https://en.wikipedia.org/wiki/Gaussian_integral#n-dimensional_and_functional_generalization" rel="external nofollow noopener" target="_blank">multivariate Gaussian integral</a>. According to Schwarz this can be further simplified for large \(N\) as</p> \[p(\boldsymbol{y} | M_i) \propto e^{\ell(\hat{\boldsymbol{\theta}}_i)} N^{-T_i/2} = e^{-\tfrac{1}{2}\text{BIC}(M_i)},\] <p>where \(\text{BIC}(M_i) \equiv -2 \ell(\hat{\boldsymbol{\theta}}_i)) + T_i \log(N)\) is the <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion" rel="external nofollow noopener" target="_blank">Bayesian Information Criterion</a> - a common in-sample measure used in identifying the “goodness of fit” of a model balanced against its complexity. Plugging this into \eqref{bayes} and taking a flat prior on the model space \(\mathbb{M}\) we finally arrive at the following expression for data-driven model probabilities:</p> <p>\begin{equation}\label{pm} p(M_i | \boldsymbol{y}) = \frac{e^{-\tfrac{1}{2}\text{BIC}(M_i)}}{ \sum_{j=1}^K e^{-\tfrac{1}{2}\text{BIC}(M_j)}}. \end{equation}</p> <p>Simply put: when all models have equal complexity we simply weigh their predictions based on their likelihood function.</p> <h3 id="towards-generality">Towards Generality</h3> <p>If practitioners of data science are put off by Bayesian information criterions, likelihood functions etc. I wouldn’t hold it against them. While these concepts are prevalent within statistics, they are less ubiquitous amongst computer scientists: indeed, they may not even be well-defined for many of the machine learning models commonly employed today. Further work is therefore warranted. Here, I’ll present a <a href="https://en.wikipedia.org/wiki/Wittgenstein%27s_ladder" rel="external nofollow noopener" target="_blank">Wittgenstein’s ladder</a>-type argument for what I think ought to be done.</p> <blockquote> <p>“<em>My propositions serve as elucidations in the following way: anyone who understands me eventually recognizes them as nonsensical, when he has used them—as steps—to climb beyond them. He must, so to speak, throw away the ladder after he has climbed up it</em>”.</p> </blockquote> <p>Suppose we have some model \(M_i: \boldsymbol{y}_t = f(\boldsymbol{x}_t \vert \boldsymbol{\theta}_i) + \varepsilon_t\) for \(t=1,2,...,N\) where \(\varepsilon_t \sim \mathcal{N}(0,\sigma_i^2)\) is an i.i.d. error term. The likelihood function for this model can be written as</p> \[L(\boldsymbol{\theta}_i) = \prod_{t=1}^N \frac{ e^{-\frac{(y_t - f(\boldsymbol{x}_t \vert \boldsymbol{\theta}_i))^2}{2\sigma_i^2}}}{\sqrt{2 \pi \sigma_i^2}},\] <p>or in log-likelihood terms:</p> \[\ell(\boldsymbol{\theta}_i) = - \frac{N}{2} \ln(2 \pi) - \frac{N}{2} \ln(\sigma_i^2) - \frac{1}{2\sigma_i^2} RSS_i,\] <p>where \(RSS_i\) is the <a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares" rel="external nofollow noopener" target="_blank">residual sum of sqaures</a>. Now \(\sigma_i^2 \approx RSS_i/N = MSE_i\) (the mean squared error) so this expression boils down to</p> \[\ell(\boldsymbol{\theta}_i) = -\frac{N}{2} \ln(MSE_i) + \text{terms depending on }N.\] <p>Hence the Bayesian information criterion can be written as</p> \[BIC(M_i) = \frac{N}{2} \ln(MSE_i) + T_i \log(N).\] <p>This offers a somewhat more appealing way of writing \eqref{pm}, with the caveat that we still have to deal with quantifying model complexity (the \(T_i\) penalty term). Now in practice what I would do instead is the following: It is well known that minimising the BIC asymptotically is equivalent to leave-of-\(\nu\) cross-validation for linear models (see <a href="https://robjhyndman.com/hyndsight/crossvalidation/" rel="external nofollow noopener" target="_blank">this reference</a>). This suggests the following approach: for each model tune hyper-parameters using cross-validation. Rather than weighing predictions of the tuned models by their \(BIC\)-score, let’s weigh them by their cross-validated mean square error. Something as simple as</p> <p>\begin{equation}\label{pm2} p(M_i | \boldsymbol{y}) = \frac{ MSE_{i,cv}^{-1} }{ \sum_{j=1}^K MSE_{j,cv}^{-1}}, \end{equation}</p> <p>could do. The benefits of this are as follows: (a) it is extremely simple to calculate, and (b) no unfair advantage is given to over-fitting models.</p> <p>Again note that this argument is purely heuristic in nature. I welcome alternative suggestions to this intensely fascinating subject.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>For a more careful derivation I recommend Bhat and Kumar’s <a href="https://faculty.ucmerced.edu/hbhat/BICderivation.pdf" rel="external nofollow noopener" target="_blank">On the derivation of the Bayesian Information Criterion</a>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Simon Ellersgaard Nielsen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>